{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from skvideo.io import vreader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import os\n",
    "#Length of the extracted feature\n",
    "FEATURE_LENGTH = 3\n",
    "#How many frames to sample from a video\n",
    "SAMPLE_NUM = 50 \n",
    "#The method for frame sampling from a video\n",
    "SAMPLE_METHOD = \"random_K\"\n",
    "root = \"/home/jeffshih/work/develop/ND_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_length(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    i = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        i +=1 \n",
    "    return i\n",
    "\n",
    "\n",
    "def get_video_paths(target_dir):\n",
    "    video_paths = glob.glob(target_dir + \"/*.mp4\")\n",
    "    return video_paths\n",
    "\n",
    "def extract_frames(video_path, samples=3, method=\"top_K\"):\n",
    "    \n",
    "    frames = []\n",
    "    if method == \"top_K\":\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            frames.append(frame)\n",
    "            if len(frames) >= samples:\n",
    "                return frames\n",
    "\n",
    "            \n",
    "        \n",
    "    elif method == \"random_K\":\n",
    "        video_length = get_video_length(video_path)\n",
    "        sample_index = np.random.choice(video_length, samples)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        i = 0\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if frame is None:\n",
    "                break\n",
    "            elif i in sample_index:\n",
    "                frames.append(frame)\n",
    "\n",
    "            i +=1 \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def extract_feature(img):\n",
    "    frame = img\n",
    "    roiWid = 10\n",
    "    #roiEdg = 8\n",
    "    roiEdg = 10\n",
    "    src_height, src_width, src_channels = frame.shape\n",
    "    roiX = int(src_width / roiWid)\n",
    "    roiWidth = roiX * roiEdg\n",
    "    roiY = int(src_height / roiWid)\n",
    "    roiHeight = roiY * roiEdg\n",
    "    RoiImg = frame[roiY : roiY+roiHeight, roiX : roiX+roiWidth]\n",
    "    \n",
    "    \n",
    "    HSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(HSV)\n",
    "    Vue_STD = np.std(V)\n",
    "    Gimg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    G_STD = np.std(Gimg)\n",
    "    hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "    hist_STD = np.std(hist)\n",
    "    hist_Mean = np.mean(hist)\n",
    "    r = img[...,2]\n",
    "    g = img[...,1]\n",
    "    b = img[...,0]\n",
    "    rY = 0.212655;\n",
    "    gY = 0.715158;\n",
    "    bY = 0.072187;\n",
    "    inner = RoiImg\n",
    "    ir = inner[...,2]\n",
    "    ig = inner[...,1]\n",
    "    ib = inner[...,0]\n",
    "\n",
    "    Luminance = r*0.2126+g*0.7152+0.0722*b\n",
    "    Li = ir*0.2126+ig*0.7152+0.0722*ib\n",
    "    hei,wid,chan = img.shape\n",
    "    ih,iw,ic = inner.shape\n",
    "    Lum_value = (np.sum(Luminance)-np.sum(Li))/((hei*wid*255)-(ih*iw*255))\n",
    "    \n",
    "    mr = np.sqrt((np.mean(r)-119)*(np.mean(r)-119))\n",
    "    mg = np.sqrt((np.mean(g)-119)*(np.mean(g)-119))\n",
    "    mb = np.sqrt((np.mean(b)-119)*(np.mean(b)-119))\n",
    "    GW_value = (mr+mg+mb)/(3*255)\n",
    "    \n",
    "    return (Vue_STD,Lum_value,G_STD,GW_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is for retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(root):\n",
    "    input_dirs = {\"light\":\"Video_Light\", \"dark\":\"Video_Dark\"}\n",
    "    frames = []\n",
    "    Y = []\n",
    "    Xl = []\n",
    "    Xd = []\n",
    "    os.chdir(root)\n",
    "    frame_cnt = 0\n",
    "    for luminance, input_dir in input_dirs.items():\n",
    "        is_dark = True if luminance == \"dark\" else False   \n",
    "        video_paths = get_video_paths(input_dir)\n",
    "        #print video_paths\n",
    "        for video_path in video_paths:\n",
    "            os.chdir(root)\n",
    "            new_frame = extract_frames(video_path, SAMPLE_NUM, SAMPLE_METHOD)\n",
    "            Y += ([is_dark] * len(new_frame))\n",
    "            for frame in new_frame :\n",
    "                frame = cv2.resize(frame,(150,120))\n",
    "                if (is_dark):\n",
    "                    Xd.append(extract_feature(frame))\n",
    "                else:\n",
    "                    Xl.append(extract_feature(frame)) \n",
    "                frame_cnt +=1\n",
    "            print \"Processing : \" + video_path\n",
    "\n",
    "\n",
    "    Y = np.array(Y, dtype=bool)\n",
    "    X = Xl + Xd\n",
    "    return Xl,Xd,X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Video_Dark/Webcam_South_pm2.mp4', 'Video_Dark/Central_Memorial_pm.mp4', 'Video_Dark/8_StreetCalgary_pm.mp4', 'Video_Dark/Free_Preview_pm.mp4', 'Video_Dark/Two_Friends_Roof_pm.mp4', 'Video_Dark/LIVE_Berlin_pm2.mp4', \"Video_Dark/City_Toomer's_pm_2.mp4\", 'Video_Dark/Sweetwater_TN.mp4', \"Video_Dark/City_Toomer's_pm_3.mp4\", 'Video_Dark/Grand_Avenue_pm.mp4', 'Video_Dark/Last _Purple_pm.mp4', 'Video_Dark/City_Auburn_Ross _pm2.mp4', 'Video_Dark/Webcam_South_pm3.mp4', 'Video_Dark/Free_Preview_pm2.mp4', \"Video_Dark/Moe's_BBQ_pm_2.mp4\", 'Video_Dark/LIVE_Berlin_pm.mp4', \"Video_Dark/Moe's_BBQ_am.mp4\", 'Video_Dark/Teton_Village_pm.mp4', 'Video_Dark/Archie_Europe_pm.mp4', 'Video_Dark/Two_Cruise_Ships.mp4', 'Video_Dark/RailCam_Road_pm.mp4', \"Video_Dark/City_Toomer's_pm.mp4\", 'Video_Dark/City_Auburn_Ross _pm.mp4', 'Video_Dark/Two_Friends_Roof_am.mp4', 'Video_Dark/Varanger_Kirkenes.mp4', \"Video_Dark/Moe's_BBQ_pm_3.mp4\", 'Video_Dark/Chioggia_Sotto_pm.mp4', 'Video_Dark/LIVE_Berlin_pm3.mp4', \"Video_Dark/City_Auburn_Toomer's.mp4\", 'Video_Dark/Webcam_South_pm1.mp4', 'Video_Dark/Rustic_Inn.mp4', \"Video_Dark/City_Toomer's_am_2.mp4\"]\n",
      "Processing : Video_Dark/Webcam_South_pm2.mp4\n",
      "Processing : Video_Dark/Central_Memorial_pm.mp4\n",
      "Processing : Video_Dark/8_StreetCalgary_pm.mp4\n",
      "Processing : Video_Dark/Free_Preview_pm.mp4\n",
      "Processing : Video_Dark/Two_Friends_Roof_pm.mp4\n",
      "Processing : Video_Dark/LIVE_Berlin_pm2.mp4\n",
      "Processing : Video_Dark/City_Toomer's_pm_2.mp4\n",
      "Processing : Video_Dark/Sweetwater_TN.mp4\n",
      "Processing : Video_Dark/City_Toomer's_pm_3.mp4\n",
      "Processing : Video_Dark/Grand_Avenue_pm.mp4\n",
      "Processing : Video_Dark/Last _Purple_pm.mp4\n",
      "Processing : Video_Dark/City_Auburn_Ross _pm2.mp4\n",
      "Processing : Video_Dark/Webcam_South_pm3.mp4\n",
      "Processing : Video_Dark/Free_Preview_pm2.mp4\n",
      "Processing : Video_Dark/Moe's_BBQ_pm_2.mp4\n",
      "Processing : Video_Dark/LIVE_Berlin_pm.mp4\n",
      "Processing : Video_Dark/Moe's_BBQ_am.mp4\n",
      "Processing : Video_Dark/Teton_Village_pm.mp4\n",
      "Processing : Video_Dark/Archie_Europe_pm.mp4\n",
      "Processing : Video_Dark/Two_Cruise_Ships.mp4\n",
      "Processing : Video_Dark/RailCam_Road_pm.mp4\n",
      "Processing : Video_Dark/City_Toomer's_pm.mp4\n",
      "Processing : Video_Dark/City_Auburn_Ross _pm.mp4\n",
      "Processing : Video_Dark/Two_Friends_Roof_am.mp4\n",
      "Processing : Video_Dark/Varanger_Kirkenes.mp4\n",
      "Processing : Video_Dark/Moe's_BBQ_pm_3.mp4\n",
      "Processing : Video_Dark/Chioggia_Sotto_pm.mp4\n",
      "Processing : Video_Dark/LIVE_Berlin_pm3.mp4\n",
      "Processing : Video_Dark/City_Auburn_Toomer's.mp4\n",
      "Processing : Video_Dark/Webcam_South_pm1.mp4\n",
      "Processing : Video_Dark/Rustic_Inn.mp4\n",
      "Processing : Video_Dark/City_Toomer's_am_2.mp4\n",
      "['Video_Light/Camera_Taipei_pm.mp4', 'Video_Light/Taipei_am.mp4', 'Video_Light/Central_Memorial_am.mp4', 'Video_Light/Taipei_am_2.mp4', 'Video_Light/UNSTOPPABLE.mp4', 'Video_Light/Train_goes_into.mp4', 'Video_Light/Soborna_am3.mp4', 'Video_Light/CSX_Freight1.mp4', 'Video_Light/Feed_MELBOURNE_am.mp4', 'Video_Light/Ashland_Train_2.mp4', 'Video_Light/Tokyo_City.mp4', 'Video_Light/Two_Cruise_Ships_am.mp4', 'Video_Light/8_StreetCalgary_am_2.mp4', 'Video_Light/Ashland_Train.mp4', 'Video_Light/8_StreetCalgary_am.mp4', 'Video_Light/RailCam_Road_am.mp4', 'Video_Light/Soborna_am2.mp4', 'Video_Light/Chioggia_Sotto2.mp4', 'Video_Light/Teton_Village_am.mp4', 'Video_Light/Tokyo_City_am.mp4', 'Video_Light/Taiwan_Live_am0.mp4', 'Video_Light/Taiwan_view.mp4', 'Video_Light/Soborna_am.mp4', 'Video_Light/awesome_Super2.mp4', 'Video_Light/Last _Purple_am.mp4', 'Video_Light/Venice_Italy_Live_Cam.mp4', 'Video_Light/Soborna_am1.mp4', 'Video_Light/awesome_Super.mp4', 'Video_Light/Taiwan_Stream_am.mp4', 'Video_Light/Morning_Rush.mp4', 'Video_Light/CSX_Freight2.mp4', 'Video_Light/LIVE_Berlin_am.mp4']\n",
      "Processing : Video_Light/Camera_Taipei_pm.mp4\n",
      "Processing : Video_Light/Taipei_am.mp4\n",
      "Processing : Video_Light/Central_Memorial_am.mp4\n",
      "Processing : Video_Light/Taipei_am_2.mp4\n",
      "Processing : Video_Light/UNSTOPPABLE.mp4\n",
      "Processing : Video_Light/Train_goes_into.mp4\n",
      "Processing : Video_Light/Soborna_am3.mp4\n",
      "Processing : Video_Light/CSX_Freight1.mp4\n",
      "Processing : Video_Light/Feed_MELBOURNE_am.mp4\n",
      "Processing : Video_Light/Ashland_Train_2.mp4\n",
      "Processing : Video_Light/Tokyo_City.mp4\n",
      "Processing : Video_Light/Two_Cruise_Ships_am.mp4\n",
      "Processing : Video_Light/8_StreetCalgary_am_2.mp4\n",
      "Processing : Video_Light/Ashland_Train.mp4\n",
      "Processing : Video_Light/8_StreetCalgary_am.mp4\n",
      "Processing : Video_Light/RailCam_Road_am.mp4\n",
      "Processing : Video_Light/Soborna_am2.mp4\n",
      "Processing : Video_Light/Chioggia_Sotto2.mp4\n",
      "Processing : Video_Light/Teton_Village_am.mp4\n",
      "Processing : Video_Light/Tokyo_City_am.mp4\n",
      "Processing : Video_Light/Taiwan_Live_am0.mp4\n",
      "Processing : Video_Light/Taiwan_view.mp4\n",
      "Processing : Video_Light/Soborna_am.mp4\n",
      "Processing : Video_Light/awesome_Super2.mp4\n",
      "Processing : Video_Light/Last _Purple_am.mp4\n",
      "Processing : Video_Light/Venice_Italy_Live_Cam.mp4\n",
      "Processing : Video_Light/Soborna_am1.mp4\n",
      "Processing : Video_Light/awesome_Super.mp4\n",
      "Processing : Video_Light/Taiwan_Stream_am.mp4\n",
      "Processing : Video_Light/Morning_Rush.mp4\n",
      "Processing : Video_Light/CSX_Freight2.mp4\n",
      "Processing : Video_Light/LIVE_Berlin_am.mp4\n"
     ]
    }
   ],
   "source": [
    "#Xl,Xd,X,Y = generate_data(root)\n",
    "Xl_testset, Xd_testset, X_testset, Y_testset = generate_data(\"/home/jeffshih/work/develop/ND_classifier/Test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567 3137\n",
      "0.499521836149\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(0,len(X_testset)):\n",
    "    Y = SVM_classifier_normalized.predict([X_testset[i]])\n",
    "    if (Y == Y_testset[i]):\n",
    "        cnt +=1\n",
    "        \n",
    "print cnt,len(Y_testset)\n",
    "print float(cnt)/len(Y_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 762\n",
      "0.746719160105\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "SVM_classifier = svm.SVC(gamma = 0.001)\n",
    "\n",
    "#Xl,Xd,X,Y = generate_data(root)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "SVM_classifier.fit(X_train,Y_train)\n",
    "predicted = SVM_classifier.predict(X_test)\n",
    "cnt = 0\n",
    "for i in range(0,len(predicted)):\n",
    "    if (predicted[i] == Y_test[i]):\n",
    "        cnt +=1\n",
    "print cnt,len(predicted)\n",
    "print float(cnt)/len(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_list = []\n",
    "test_label_list = []\n",
    "for root, subroot, files in os.walk(\"./Test_data\"):\n",
    "    for file_name in files :\n",
    "        if file_name.endswith(\"jpg\"):\n",
    "            test_file_list.append(os.path.join(root,file_name))\n",
    "            if \"Dark\" in root :\n",
    "                test_label_list.append(True)\n",
    "            else:\n",
    "                test_label_list.append(False)   \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in range(0,len(test_label_list)):\n",
    "    img = test_file_list[i]\n",
    "    img = cv2.imread(img)\n",
    "    #feature = [extract_feature(img)]\n",
    "    #Y = SVM_classifier.predict(feature)\n",
    "    #Y_.append(Y)\n",
    "    inp = extract_feature(img)\n",
    "    features.append(inp)\n",
    "    #if (Y[0] == test_label_list[i]):\n",
    "    #    cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "normalized_feature = preprocessing.normalize(features)\n",
    "normalized_X = preprocessing.normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "os.chdir(root)\n",
    "SVM_classifier = joblib.load('SVM_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the split from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [762, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f2a99b2b5e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Xl,Xd,X,Y = generate_data(root)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#SVM_classifier_normalized = svm.SVC(gamma = 0.001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#SVM_classifier_normalized.fit(normalized_feature,test_label_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [762, 1]"
     ]
    }
   ],
   "source": [
    "#Xl,Xd,X,Y = generate_data(root)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(normalized_X, Y, test_size=0.1, random_state=1)\n",
    "#SVM_classifier_normalized = svm.SVC(gamma = 0.001)\n",
    "#SVM_classifier_normalized.fit(normalized_feature,test_label_list)\n",
    "predicted = SVM_classifier.predict(X_test)\n",
    "cnt = 0\n",
    "for i in range(0,len(predicted)):\n",
    "    if (predicted[i] == Y_test[i]):\n",
    "        cnt +=1\n",
    "print cnt,len(predicted)\n",
    "print float(cnt)/len(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the seperate image set to eliminate the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41112701984\n",
      "4889\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "Y_ = []\n",
    "features = []\n",
    "\n",
    "for i in range(0,len(test_label_list)):\n",
    "    img = test_file_list[i]\n",
    "    img = cv2.imread(img)\n",
    "    #feature = [extract_feature(img)]\n",
    "    #Y = SVM_classifier.predict(feature)\n",
    "    #Y_.append(Y)\n",
    "    inp = extract_feature(img)\n",
    "    features.append(inp)\n",
    "    if (inp[0] > 0.55):\n",
    "        Y = True\n",
    "    if (Y == test_label_list[i]):\n",
    "        cnt +=1\n",
    "    #break\n",
    "        \n",
    "print float(cnt) / len(test_label_list)\n",
    "print len(test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 762\n",
      "0.368766404199\n"
     ]
    }
   ],
   "source": [
    "SVM_new = svm.SVC(gamma = 0.0001)\n",
    "SVM_new.fit(features,test_label_list)\n",
    "\n",
    "predicted = SVM_new.predict(X_test)\n",
    "cnt = 0\n",
    "for i in range(0,len(predicted)):\n",
    "    if (predicted[i] == Y_test[i]):\n",
    "        cnt +=1\n",
    "print cnt,len(predicted)\n",
    "print float(cnt)/len(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(SVM_classifier,'SVM_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For plotting, can not execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121,projection ='3d')\n",
    "ax.scatter([i[0] for i in Xl],[i[2] for i in Xl],[i[1] for i in Xl],c='r',marker = 'o')\n",
    "ax.scatter([i[0] for i in Xd],[i[2] for i in Xd],[i[1] for i in Xd],c='b',marker = 'x')\n",
    "ax.view_init(45, 45)\n",
    "ax1 = fig.add_subplot(122,projection ='3d')\n",
    "ax1.scatter([i[0] for i in Xl],[i[2] for i in Xl],[i[1] for i in Xl],c='r',marker = 'o')\n",
    "ax1.scatter([i[0] for i in Xd],[i[2] for i in Xd],[i[1] for i in Xd],c='b',marker = 'x')\n",
    "ax1.view_init(0, 113)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "src = '/home/jeffshih/work/develop/ND_classifier/Test_data/Dark_image_2/N029.jpg'\n",
    "img = cv2.imread(src)\n",
    "%timeit extract_feature(img)\n",
    "feature = [extract_feature(img)]\n",
    "%timeit SVM_classifier.predict(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
